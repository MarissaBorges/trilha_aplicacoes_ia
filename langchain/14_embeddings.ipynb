{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab99ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40fddf28",
   "metadata": {},
   "source": [
    "Os Embeddings criam uma representação vetorial de um pedaço de texto. Isso é útil porque significa que podemos pensar sobre o texto no espaço vetorial e fazer coisas como busca semântica, onde procuramos por pedaços de texto que são mais semelhantes no espaço vetorial, ou seja, que estão a uma distância menor.\n",
    "\n",
    "A classe Embeddings do Langchain é uma classe projetada para interagir com modelos de embedding de texto. Existem muitos modelos diferentes (OpenAI, Cohere, Hugging Face, etc) - esta classe é projetada para fornecer uma interface padrão para todos eles.\n",
    "\n",
    "A classe de Embeddings base em LangChain fornece dois métodos: um para realizar o emedding de documentos e outro para embedding de uma chamada. O primeiro recebe como entrada vários textos, enquanto o último recebe um único texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ecb96f8",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/text_embedding/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05996bd",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75b6dcb5",
   "metadata": {},
   "source": [
    "## Embeddings com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06928c56",
   "metadata": {},
   "source": [
    "### Embedding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bafa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu gosto de cachorros',\n",
    "        'Eu gosto de animais',\n",
    "        'O tempo esta ruim lá fora'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664d424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a5a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01189151406288147,\n",
       " 0.003109192941337824,\n",
       " -0.008564830757677555,\n",
       " -0.02842690609395504,\n",
       " -0.021332433447241783,\n",
       " 0.0040618618950247765,\n",
       " 0.007443683221936226,\n",
       " -0.014335982501506805,\n",
       " 0.0038933833129704,\n",
       " -0.007805146276950836]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a60d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4c4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74263176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8685d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536 0.24662791192531586 -0.6614646911621094\n",
      "1536 0.23287081718444824 -0.654877245426178\n",
      "1536 0.2336682230234146 -0.6505195498466492\n"
     ]
    }
   ],
   "source": [
    "for emb in embeddings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c223c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929192296639189"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86f6a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7983246984344478"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embeddings[1], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12de8719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104247627189738"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embeddings[2], embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "681365b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.93 | 0.81 | \n",
      "0.93 | 1.0 | 0.8 | \n",
      "0.81 | 0.8 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(round(np.dot(embeddings[i], embeddings[j]), 2), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7302fad",
   "metadata": {},
   "source": [
    "### Embedding query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f6ef1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005100993439555168,\n",
       " 0.003876505186781287,\n",
       " -0.0046824184246361256,\n",
       " -0.006441058591008186,\n",
       " -0.017842544242739677,\n",
       " 0.013619309291243553,\n",
       " 0.0015954270493239164,\n",
       " -0.002005412010475993,\n",
       " -0.002075695199891925,\n",
       " 0.005591413471847773]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'O que é um cachorro?'\n",
    "emb_query = embedding_model.embed_query(pergunta)\n",
    "emb_query[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e82ced4a",
   "metadata": {},
   "source": [
    "## Embedding com HuggingFace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad11d8d7",
   "metadata": {},
   "source": [
    "https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d73f5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Documentos\\Trabalho\\Programacao\\trilha_aplicacoes_ia\\venv311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\Documentos\\Trabalho\\Programacao\\trilha_aplicacoes_ia\\venv311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maris\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model = 'all-MiniLM-L6-v2'\n",
    "embedding_model = HuggingFaceBgeEmbeddings(model_name=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af3726eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu gosto de cachorros',\n",
    "        'Eu gosto de animais',\n",
    "        'O tempo esta ruim lá fora'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38518b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.68 | 0.4 | \n",
      "0.68 | 1.0 | 0.49 | \n",
      "0.4 | 0.49 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(round(np.dot(embeddings[i], embeddings[j]), 2), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfd4c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 0.1526719629764557 -0.13653476536273956\n",
      "384 0.12528783082962036 -0.1534135341644287\n",
      "384 0.12505868077278137 -0.13441646099090576\n"
     ]
    }
   ],
   "source": [
    "for emb in embeddings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
